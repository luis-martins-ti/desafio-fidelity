# desafio-fidelity
Refactor aplicaÃ§Ã£o de Web Scraping com estrutura Docker. AplicaÃ§Ã£o desenvolvida com Python + Django.
Foram criadas novas entidades para atender as necessidades das chaves estrangeiras e remodelado a estrutura geral dos dados.
Para modularizar as consultas em outras plataformas, Ã© necessÃ¡rio criar o MAP dos elementos e aÃ§Ãµes que o selenium deve executar e gerar uma classe
com as opÃ§Ãµes para uso no mÃ©todo carrega_site. 

## ğŸš€ Como iniciar o projeto

### âœ… PrÃ©-requisitos
- Docker + Docker Compose

---

### ğŸ§± STEP 1 - Build e start com Docker

**Renomeie o arquivo .env.example para .env e execute:**

```bash
docker compose build --no-cache
docker compose up -d
```

### ğŸ“¦ STEP 2 - Criar Dados para Testes
**Aguarde alguns segundos para a aplicaÃ§Ã£o iniciar e execute:**

```bash
docker compose exec web python manage.py populate_pesquisas
```

### ğŸ–¥ï¸ STEP 3 - Executar a aplicaÃ§Ã£o

```bash
docker compose exec web python manage.py run_spv
#Executa com filtro especÃ­fico
docker compose exec web python manage.py run_spv --filtro 2
```

### ğŸ–¥ï¸ STEP 4 - Visualizar os Resultados

```bash
docker compose exec web python manage.py list_pesquisa_spv
```


### ğŸ“˜ Tecnologias Utilizadas
- Django
- Python
- PostgreSQL
- Docker
- Selenium Web Driver

**Para encerrar a aplicaÃ§Ã£o rodar:**
```bash
docker compose down -v --remove-orphans
```